<!DOCTYPE html>
<html lang="en" dir="auto" data-theme="dark">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>HPC-1-divide-and-conquer-block-matrix-algorithmr | Xi&#39;s Blog</title>
<meta name="keywords" content="matrix-multiplication, cache-optimization, SIMD, intrinsics">
<meta name="description" content="week 2 block matrix algorithm
1. BLIS reference high performance implitation v.s. naive methods:

2. With different block size:
This is the MB NB PB = 40.
But if the block size is too small, the performance is not as good as naive PJI.
The front for loop is JIP is not related to the performance of the algorithm because the computer will focus on each implementation in blocking. That means the register will focus on optimize the final for loop: the Gemm_JPI function, but will not paralize and optimize the for loop for block - matrix- matrix - multiplication.">
<meta name="author" content="Xi Chen">
<link rel="canonical" href="http://localhost:1313/posts/2023-04-14-hpc1-divide-and-conquer-block-matrix/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.56bf4be95d09faf55cd507c845718ccfcabb2e24e37f8fa5a66f9fa098252b06.css" integrity="sha256-Vr9L6V0J&#43;vVc1QfIRXGMz8q7LiTjf4&#43;lpm&#43;foJglKwY=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/2023-04-14-hpc1-divide-and-conquer-block-matrix/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<script>
    if (localStorage.getItem("pref-theme") === "light") {
        document.querySelector("html").dataset.theme = 'light';
    }

</script>
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    displayMath: [['$$', '$$'], ['\\[', '\\]']],
    processEscapes: true,
    processEnvironments: true
  },
  options: {
    skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
};

window.addEventListener('load', (event) => {
    document.querySelectorAll("mjx-container").forEach(function(x){
      x.parentElement.classList += 'has-jax'})
  });
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</head>
<body id="top">
    <header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Xi&#39;s Blog (Alt + H)">Xi&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;»&nbsp;<a href="http://localhost:1313/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      HPC-1-divide-and-conquer-block-matrix-algorithmr
    </h1>
    <div class="post-meta"><span title='2024-04-15 00:05:14 -0400 EDT'>April 15, 2024</span>&nbsp;·&nbsp;<span>9 min</span>&nbsp;·&nbsp;<span>1852 words</span>&nbsp;·&nbsp;<span>Xi Chen</span>

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><nav id="TableOfContents">
  <ul>
    <li><a href="#41-analysis">4.1 analysis</a></li>
    <li><a href="#42--streaming-operationjip_p_ger">4.2  Streaming operation:JIP_P_Ger</a></li>
    <li><a href="#43-micro-kernel-jip_p_ger">4.3 Micro Kernel :JIP_P_Ger</a></li>
  </ul>

  <ul>
    <li><a href="#51-vector-register">5.1 vector register</a></li>
    <li><a href="#52-best-performance-analysis-of-the-data-transferring-cost-when-the-register-memory-is-limited">5.2 Best performance analysis of the data transferring cost when the register memory is limited.</a></li>
    <li><a href="#appendix-i">Appendix I</a></li>
    <li><a href="#appendix-ii">Appendix II</a></li>
  </ul>
</nav>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="week-2-block-matrix-algorithm">week 2 block matrix algorithm<a hidden class="anchor" aria-hidden="true" href="#week-2-block-matrix-algorithm">#</a></h1>
<h1 id="1-blis-reference-high-performance-implitation-vs-naive-methods">1. BLIS reference high performance implitation v.s. naive methods:<a hidden class="anchor" aria-hidden="true" href="#1-blis-reference-high-performance-implitation-vs-naive-methods">#</a></h1>
<p><img alt="img" loading="lazy" src="https://raw.githubusercontent.com/xichen1997/picture_for_blog/master/Plot_All_Orderings.png"></p>
<h1 id="2-with-different-block-size">2. With different block size:<a hidden class="anchor" aria-hidden="true" href="#2-with-different-block-size">#</a></h1>
<p>This is the MB NB PB = 40.</p>
<p>But if the block size is too small, the performance is not as good as naive PJI.</p>
<p>The front for loop is JIP is not related to the performance of the algorithm because the computer will focus on each implementation in blocking. That means the register will focus on optimize the final for loop: the Gemm_JPI function, but will not paralize and optimize the for loop for block - matrix- matrix - multiplication.</p>
<p><img alt="img" loading="lazy" src="https://raw.githubusercontent.com/xichen1997/picture_for_blog/master/Plot_Blocked_MMM.png"></p>
<h1 id="3-memory-and-register-model">3. memory and register model.<a hidden class="anchor" aria-hidden="true" href="#3-memory-and-register-model">#</a></h1>
<p><img alt="img" loading="lazy" src="https://raw.githubusercontent.com/xichen1997/picture_for_blog/master/20241025123736.png"></p>
<p>The relation of register and main memory can be shown as above, then we assume that when we computing we can&rsquo;t transfer data. The cost of transferring data is $R_m$</p>
<p>The register can hold 64 doubles(512 bytes)</p>
<h1 id="4-a-example-of-how-register-works">4. A example of how register works.<a hidden class="anchor" aria-hidden="true" href="#4-a-example-of-how-register-works">#</a></h1>
<h2 id="41-analysis">4.1 analysis<a hidden class="anchor" aria-hidden="true" href="#41-analysis">#</a></h2>
<p><img alt="img" loading="lazy" src="http://www.cs.utexas.edu/users/flame/laff/pfhp/images/Week2/GemmIJPIJP.png"></p>
<p>This is a exmple of using block matrix to update part of the final answer.</p>
<p>Assuming the CPU needs to spend $\gamma_R$ time for each floating-point operation and $\beta_{R \leftrightarrow M}$ time to transfer data between registers and memory, the total cost for the operation is:</p>
<p>$$
\begin{aligned}
&amp; MNK \left( (m_R n_R + m_R k_R + k_R n_R) \beta_{R \leftrightarrow M} + 2 m_R n_R k_R \gamma_R + m_R n_R \beta_{R \leftrightarrow M} \right) \\
&amp;= 2 (M m_R)(N n_R)(K k_R) \gamma_R + 2 (M m_R)(N n_R) K \beta_{R \leftrightarrow M} \\
&amp;\quad + (M m_R) N (K k_R) \beta_{R \leftrightarrow M} + M (N n_R)(K k_R) \beta_{R \leftrightarrow M} \\
&amp;= 2 m n k \gamma_R + m n k \left( \frac{2}{k_R} + \frac{1}{n_R} + \frac{1}{m_R} \right) \beta_{R \leftrightarrow M}
\end{aligned}
$$</p>
<p>The process is:</p>
<p>$$
\begin{aligned}
&amp; \text{for } j = 0, \ldots, N-1 \\
&amp; \quad \text{for } i = 0, \ldots, M-1 \\
&amp; \quad \quad \text{for } p = 0, \ldots, K-1 \\
&amp; \quad \quad \quad \text{Load } C_{i,j}, A_{i,p}, \text{ and } B_{p,j} \text{ into registers} \\
&amp; \quad \quad \quad C_{i,j} := A_{i,p} B_{p,j} + C_{i,j} \\
&amp; \quad \quad \quad \text{Store } C_{i,j} \text{ to memory}
\end{aligned}
$$</p>
<p>But we could do better by saving $C_{ij}$ before the P loop:</p>
<p>$$
\begin{aligned}
&amp; \text{for } j = 0, \ldots, N-1 \\
&amp; \quad \text{for } i = 0, \ldots, M-1 \\
&amp; \quad \quad \text{Load } C_{i,j} \\
&amp; \quad \quad \text{for } p = 0, \ldots, K-1 \\
&amp; \quad \quad \quad \text{Load } A_{i,p} \text{ and } B_{p,j} \text{ into registers} \\
&amp; \quad \quad \quad C_{i,j} := A_{i,p} B_{p,j} + C_{i,j} \\
&amp; \quad \quad \text{Store } C_{i,j}
\end{aligned}
$$</p>
<p>Then the final computational time is:</p>
<p>$$
\begin{aligned}
&amp; MNK(2m_Rn_Rk_R)\gamma_R + [MN(2m_Rn_R) + MNK(m_Rk_R + k_Rn_R)]\beta_{R \leftrightarrow M} \\
&amp;= 2mnk\gamma_R + \left[2mn + mnk\left(\frac{1}{n_R} + \frac{1}{m_R}\right)\right]\beta_{R \leftrightarrow M}
\end{aligned}
$$
The capital K is Larger, the saved time is more.</p>
<h2 id="42--streaming-operationjip_p_ger">4.2  Streaming operation:JIP_P_Ger<a hidden class="anchor" aria-hidden="true" href="#42--streaming-operationjip_p_ger">#</a></h2>
<p>The picture show how we do the streaming, the nature of this operation is to use rank-1 operation to update the block matrix, the rank-1 operation will continue update matrix C without changing data with main memory.</p>
<p><img alt="img" loading="lazy" src="http://www.cs.utexas.edu/users/flame/laff/pfhp/images/Week2/GemmIJPPrank1.png"></p>
<p>Every time we do streaming operation:</p>
<p><img alt="img" loading="lazy" src="http://www.cs.utexas.edu/users/flame/laff/pfhp/images/Week2/GemmIJPPrank1One.png"></p>
<p>In order to make good use of all the register memory, we can assume that $m_R$, $n_R$, and $k_R$ are the same, and assume they are 4. The overall memory in register is
$$
m_R \times n_R + m_R + n_R  = 24
$$</p>
<p><img alt="plot_register_block_4" loading="lazy" src="http://xcwp.azurewebsites.net/wp-content/uploads/2020/05/plot_register_block_4.png"></p>
<p>But the performance (use block size of 4) is not soo good.	the picture will show the block size is 400. which is much better.</p>
<p><img alt="Plot_register_blocking_400" loading="lazy" src="http://xcwp.azurewebsites.net/wp-content/uploads/2020/05/Plot_register_blocking_400.png"></p>
<h2 id="43-micro-kernel-jip_p_ger">4.3 Micro Kernel :JIP_P_Ger<a hidden class="anchor" aria-hidden="true" href="#43-micro-kernel-jip_p_ger">#</a></h2>
<p>In fact in the operation of streaming operation, we don&rsquo;t need to split the p into pk, and we can save the time for for loop:</p>
<p><img alt="img" loading="lazy" src="http://www.cs.utexas.edu/users/flame/laff/pfhp/images/Week2/GemmIJPPrank1Two.png"></p>
<h1 id="5-optimize-the-micro-kernel">5. Optimize the micro kernel<a hidden class="anchor" aria-hidden="true" href="#5-optimize-the-micro-kernel">#</a></h1>
<h2 id="51-vector-register">5.1 vector register<a hidden class="anchor" aria-hidden="true" href="#51-vector-register">#</a></h2>
<p>FMA: fused multiple add operation</p>
<p>SIMD: simple instruction multiple data</p>
<p>$$
\begin{pmatrix}
\gamma_{0,0} &amp; \gamma_{0,1} &amp; \gamma_{0,2} &amp; \gamma_{0,3} \\
\gamma_{1,0} &amp; \gamma_{1,1} &amp; \gamma_{1,2} &amp; \gamma_{1,3} \\
\gamma_{2,0} &amp; \gamma_{2,1} &amp; \gamma_{2,2} &amp; \gamma_{2,3} \\
\gamma_{3,0} &amp; \gamma_{3,1} &amp; \gamma_{3,2} &amp; \gamma_{3,3}
\end{pmatrix}
+:=
\begin{pmatrix}
\alpha_{0,p} \\
\alpha_{1,p} \\
\alpha_{2,p} \\
\alpha_{3,p}
\end{pmatrix}
\begin{pmatrix}
\beta_{p,0} &amp; \beta_{p,1} &amp; \beta_{p,2} &amp; \beta_{p,3}
\end{pmatrix}
$$</p>
<p>$$
\beta_{p,0}
\begin{pmatrix}
\alpha_{0,p} \\
\alpha_{1,p} \\
\alpha_{2,p} \\
\alpha_{3,p}
\end{pmatrix}
+
\beta_{p,1}
\begin{pmatrix}
\alpha_{0,p} \\
\alpha_{1,p} \\
\alpha_{2,p} \\
\alpha_{3,p}
\end{pmatrix}
+
\beta_{p,2}
\begin{pmatrix}
\alpha_{0,p} \\
\alpha_{1,p} \\
\alpha_{2,p} \\
\alpha_{3,p}
\end{pmatrix}
+
\beta_{p,3}
\begin{pmatrix}
\alpha_{0,p} \\
\alpha_{1,p} \\
\alpha_{2,p} \\
\alpha_{3,p}
\end{pmatrix}
$$</p>
<p>If we use SIMD:</p>
<p>$$
\begin{array}{|c|}
\hline
\gamma_{0,0} \\ \hline
\gamma_{1,0} \\ \hline
\gamma_{2,0} \\ \hline
\gamma_{3,0} \\ \hline
\end{array}
\quad
\begin{array}{c}
+:= \\
+:= \\
+:= \\
+:=
\end{array}
\quad
\begin{array}{|c|}
\hline
\alpha_{0,p} \\ \hline
\alpha_{1,p} \\ \hline
\alpha_{2,p} \\ \hline
\alpha_{3,p} \\ \hline
\end{array}
\quad
\begin{array}{c}
\times \\
\times \\
\times \\
\times
\end{array}
\quad
\begin{array}{|c|}
\hline
\beta_{p,0} \\ \hline
\beta_{p,0} \\ \hline
\beta_{p,0} \\ \hline
\beta_{p,0} \\ \hline
\end{array}
$$</p>
<p>Then implement it use the code: using AX2 intrinsic.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="cp">#define alpha( i,j ) A[ (j)*ldA + (i) ]   </span><span class="c1">// map alpha( i,j ) to array A
</span></span></span><span class="line"><span class="cl"><span class="cp">#define beta( i,j )  B[ (j)*ldB + (i) ]   </span><span class="c1">// map beta( i,j ) to array B
</span></span></span><span class="line"><span class="cl"><span class="cp">#define gamma( i,j ) C[ (j)*ldC + (i) ]   </span><span class="c1">// map gamma( i,j ) to array C
</span></span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="cp">#include&lt;immintrin.h&gt;
</span></span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">Gemm_MRxNRKernel</span><span class="p">(</span> <span class="kt">int</span> <span class="n">k</span><span class="p">,</span> <span class="kt">double</span> <span class="o">*</span><span class="n">A</span><span class="p">,</span> <span class="kt">int</span> <span class="n">ldA</span><span class="p">,</span> <span class="kt">double</span> <span class="o">*</span><span class="n">B</span><span class="p">,</span> <span class="kt">int</span> <span class="n">ldB</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">		<span class="kt">double</span> <span class="o">*</span><span class="n">C</span><span class="p">,</span> <span class="kt">int</span> <span class="n">ldC</span> <span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="cm">/* Declare vector registers to hold 4x4 C and load them */</span>
</span></span><span class="line"><span class="cl">  <span class="n">__m256d</span> <span class="n">gamma_0123_0</span> <span class="o">=</span> <span class="n">_mm256_loadu_pd</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">gamma</span><span class="p">(</span> <span class="mi">0</span><span class="p">,</span><span class="mi">0</span> <span class="p">)</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="n">__m256d</span> <span class="n">gamma_0123_1</span> <span class="o">=</span> <span class="n">_mm256_loadu_pd</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">gamma</span><span class="p">(</span> <span class="mi">0</span><span class="p">,</span><span class="mi">1</span> <span class="p">)</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="n">__m256d</span> <span class="n">gamma_0123_2</span> <span class="o">=</span> <span class="n">_mm256_loadu_pd</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">gamma</span><span class="p">(</span> <span class="mi">0</span><span class="p">,</span><span class="mi">2</span> <span class="p">)</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="n">__m256d</span> <span class="n">gamma_0123_3</span> <span class="o">=</span> <span class="n">_mm256_loadu_pd</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">gamma</span><span class="p">(</span> <span class="mi">0</span><span class="p">,</span><span class="mi">3</span> <span class="p">)</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">   	
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="p">(</span> <span class="kt">int</span> <span class="n">p</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">p</span><span class="o">&lt;</span><span class="n">k</span><span class="p">;</span> <span class="n">p</span><span class="o">++</span> <span class="p">){</span>
</span></span><span class="line"><span class="cl">    <span class="cm">/* Declare vector register for load/broadcasting beta( p,j ) */</span>
</span></span><span class="line"><span class="cl">    <span class="n">__m256d</span> <span class="n">beta_p_j</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="cm">/* Declare a vector register to hold the current column of A and load
</span></span></span><span class="line"><span class="cl"><span class="cm">       it with the four elements of that column. */</span>
</span></span><span class="line"><span class="cl">    <span class="n">__m256d</span> <span class="n">alpha_0123_p</span> <span class="o">=</span> <span class="n">_mm256_loadu_pd</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">alpha</span><span class="p">(</span> <span class="mi">0</span><span class="p">,</span><span class="n">p</span> <span class="p">)</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="cm">/* Load/broadcast beta( p,0 ). */</span>
</span></span><span class="line"><span class="cl">    <span class="n">beta_p_j</span> <span class="o">=</span> <span class="n">_mm256_broadcast_sd</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">beta</span><span class="p">(</span> <span class="n">p</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="cm">/* update the first column of C with the current column of A times
</span></span></span><span class="line"><span class="cl"><span class="cm">       beta ( p,0 ) */</span>
</span></span><span class="line"><span class="cl">    <span class="n">gamma_0123_0</span> <span class="o">=</span> <span class="n">_mm256_fmadd_pd</span><span class="p">(</span> <span class="n">alpha_0123_p</span><span class="p">,</span> <span class="n">beta_p_j</span><span class="p">,</span> <span class="n">gamma_0123_0</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="cm">/* REPEAT for second, third, and fourth columns of C.  Notice that the 
</span></span></span><span class="line"><span class="cl"><span class="cm">       current column of A needs not be reloaded. */</span>
</span></span><span class="line"><span class="cl">    <span class="n">beta_p_j</span> <span class="o">=</span> <span class="n">_mm256_broadcast_sd</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">beta</span><span class="p">(</span> <span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">gamma_0123_1</span> <span class="o">=</span> <span class="n">_mm256_fmadd_pd</span><span class="p">(</span> <span class="n">alpha_0123_p</span><span class="p">,</span> <span class="n">beta_p_j</span><span class="p">,</span> <span class="n">gamma_0123_1</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">beta_p_j</span> <span class="o">=</span> <span class="n">_mm256_broadcast_sd</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">beta</span><span class="p">(</span> <span class="n">p</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">gamma_0123_2</span> <span class="o">=</span> <span class="n">_mm256_fmadd_pd</span><span class="p">(</span> <span class="n">alpha_0123_p</span><span class="p">,</span> <span class="n">beta_p_j</span><span class="p">,</span> <span class="n">gamma_0123_2</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">beta_p_j</span> <span class="o">=</span> <span class="n">_mm256_broadcast_sd</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">beta</span><span class="p">(</span> <span class="n">p</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">gamma_0123_3</span> <span class="o">=</span> <span class="n">_mm256_fmadd_pd</span><span class="p">(</span> <span class="n">alpha_0123_p</span><span class="p">,</span> <span class="n">beta_p_j</span><span class="p">,</span> <span class="n">gamma_0123_3</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="cm">/* Store the updated results */</span>
</span></span><span class="line"><span class="cl">  <span class="n">_mm256_storeu_pd</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">gamma</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">gamma_0123_0</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="n">_mm256_storeu_pd</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">gamma</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">gamma_0123_1</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="n">_mm256_storeu_pd</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">gamma</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">gamma_0123_2</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="n">_mm256_storeu_pd</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">gamma</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">gamma_0123_3</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="n">__m256d</span> <span class="n">gamma_0123_0</span> <span class="o">=</span> <span class="n">_mm256_loadu_pd</span> <span class="err">\\\\</span> <span class="n">This</span> <span class="n">load</span> <span class="n">the</span> <span class="n">vector</span> <span class="n">which</span> <span class="n">contains</span> <span class="mi">4</span> <span class="n">doubles</span> <span class="p">(</span><span class="n">note</span> <span class="n">the</span> <span class="n">intrinsic</span> <span class="n">can</span> <span class="n">only</span> <span class="n">hold</span> <span class="mi">4</span> <span class="n">doubles</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="n">beta_p_j</span> <span class="o">=</span> <span class="n">_mm256_broadcast_sd</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">beta</span><span class="p">(</span> <span class="n">p</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="p">);</span><span class="err">\\\\</span> <span class="n">This</span> <span class="n">use</span> <span class="n">one</span> <span class="kt">double</span> <span class="n">to</span> <span class="k">do</span> <span class="n">broadcast</span><span class="p">.</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">   <span class="n">gamma_0123_0</span> <span class="o">=</span> <span class="n">_mm256_fmadd_pd</span><span class="p">(</span> <span class="n">alpha_0123_p</span><span class="p">,</span> <span class="n">beta_p_j</span><span class="p">,</span> <span class="n">gamma_0123_0</span> <span class="p">);</span><span class="err">\\\\</span> <span class="n">This</span> <span class="n">will</span> <span class="n">use</span> <span class="n">FMA</span> <span class="n">to</span> <span class="n">compute</span> <span class="n">from</span> <span class="n">two</span> <span class="n">vectors</span> <span class="n">and</span> <span class="n">accumulate</span> <span class="n">the</span> <span class="n">result</span> 
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="n">_mm256_storeu_pd</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">gamma</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">gamma_0123_0</span> <span class="p">);</span><span class="err">\\\\</span> <span class="n">This</span> <span class="n">will</span> <span class="k">return</span> <span class="n">the</span> <span class="n">memory</span> <span class="n">from</span> <span class="k">register</span> <span class="n">to</span> <span class="n">main</span><span class="o">-</span><span class="n">memory</span><span class="p">.</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="52-best-performance-analysis-of-the-data-transferring-cost-when-the-register-memory-is-limited">5.2 Best performance analysis of the data transferring cost when the register memory is limited.<a hidden class="anchor" aria-hidden="true" href="#52-best-performance-analysis-of-the-data-transferring-cost-when-the-register-memory-is-limited">#</a></h2>
<p>S is for the C matrix, M is for the matrix of B and A. Because in the end we will send all C matrix parts into register memory, so the total number of this is |C| we don&rsquo;t need to analysis. As for the B and A, because of the streaming data, we should analyze them carefully.</p>
<p>We can combine the 3 for loop and split them into different phases. at each phase, we send S+M data into the register memory. S is storage of fast memory, and M is the data need to be replaced next phase.</p>
<p>$$
\begin{aligned}
&amp; \text{for } r = 0, \ldots, mnk-1 \\
&amp; \quad \gamma_{i_r,j_r} := \alpha_{i_r,p_r} \beta_{p_r,j_r} + \gamma_{i_r,j_r} \\
&amp; \text{end}
\end{aligned}
$$</p>
<p>The overall FMAs is mnk in this equation, we assume we can have Fmax FMAs by sending the memory into register once, then we need to transfer data:</p>
<p>$$
\begin{equation*}
\left(\frac{m n k}{F_{\rm max}} -1 \right) M
\end{equation*}
$$</p>
<p>So if we choose S and M properly, we can maximize F and get the good solution of all the equation. In order to maximize F, we could use a model to abstract this procedure:</p>
<p>For a each phase, we assume a space D combined with (ir,jr,pr) tuple, In the subspace of AD, we have (ir,pr), for the subspace of BD, we have (jr, pr), in the subspace of CD, we have (ir,jr). ( r is the index of one phase.)</p>
<p>The number of the space D can be limited by this relation(3d geometry):</p>
<p>$$
\vert \mathbf{D} \vert \leq \sqrt{\vert
\mathbf{C_D} \vert \vert \mathbf{A_D} \vert \vert \mathbf{B_D}
\vert }\text{.}
$$</p>
<p>So we could limit D by these inequal:</p>
<p>$$
\begin{equation*}
{\rm maximize~} F_{\rm max} {\rm <del>such</del>that~} \left{
\begin{array}{l} F_{\rm max} \leq \sqrt{\vert \mathbf{C_D}
\vert \vert \mathbf{A_D} \vert \vert \mathbf{B_D} \vert } \\
\vert \mathbf{C_D} \vert \gt 0, \vert \mathbf{A_D} \vert \gt
0, \vert \mathbf{B_D} \vert \gt 0 \\ \vert \mathbf{C_D}
\vert + \vert \mathbf{A_D} \vert + \vert \mathbf{B_D} \vert
= S + M.  \end{array} \right.
\end{equation*}
$$</p>
<p>According to mathematical calculation, the:</p>
<p>$$
\begin{aligned}
|\mathbf{C_D}| = |\mathbf{A_D}| = |\mathbf{B_D}| &amp;= \frac{S+M}{3} \\
F_{\max} &amp;= \frac{(S + M)\sqrt{S+M}}{3\sqrt{3}}
\end{aligned}
$$</p>
<p>And:</p>
<p>$$
\begin{equation*}
\left(\frac{m n k}{F_{\rm max}} -1 \right) M =
\left(3 \sqrt{3} \frac{m n k}{( S + M )\sqrt{S+M}} -1 \right) M.
\end{equation*}
$$</p>
<p>Take the derivatives of the right hand side, we assume S is a const and M is a variable, so in the end we get:</p>
<p>$$
M=2S
$$</p>
<p>$$
\begin{equation*}
\left(3 \sqrt{3} \frac{m n k}{( 3 S  )\sqrt{3 S}} -1 \right) (2S)
= 2 \frac{m n k}{\sqrt{S}} - 2S.
\end{equation*}
$$</p>
<p>Satisfy the equation, and S+M &lt;= register memory, the S is bigger, the performance is better. and M = 2S. If we take an example, the register can hold 32 doubles, so S+M = 32, and with M = 2S, we get S = 32/3 ≈ 10.67 doubles for storage.</p>
<p>All the information are from the paper:
<a href="https://arxiv.org/pdf/1702.02017.pdf">https://arxiv.org/pdf/1702.02017.pdf</a></p>
<h2 id="appendix-i">Appendix I<a hidden class="anchor" aria-hidden="true" href="#appendix-i">#</a></h2>
<ul>
<li>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="n">__m256d</span> <span class="n">_mm256_loadu_pd</span> <span class="p">(</span><span class="kt">double</span> <span class="k">const</span> <span class="o">*</span> <span class="n">mem_addr</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Description</p>
<p>Load 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from memory into dst (output). mem_addr does not need to be aligned on any particular boundary.</p>
</li>
<li></li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="n">__m256d</span> <span class="n">_mm256_broadcast_sd</span> <span class="p">(</span><span class="kt">double</span> <span class="k">const</span> <span class="o">*</span> <span class="n">mem_addr</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Description</p>
<p>Broadcast a double-precision (64-bit) floating-point element from memory to all elements of dst (output).</p>
<ul>
<li></li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="n">__m256d</span> <span class="n">_mm256_fmadd_pd</span> <span class="p">(</span><span class="n">__m256d</span> <span class="n">a</span><span class="p">,</span> <span class="n">__m256d</span> <span class="n">b</span><span class="p">,</span> <span class="n">__m256d</span> <span class="n">c</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Description</p>
<p>Multiply packed double-precision (64-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst (output).</p>
<h2 id="appendix-ii">Appendix II<a hidden class="anchor" aria-hidden="true" href="#appendix-ii">#</a></h2>
<p>Intel intrinsics reference:</p>
<p><a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/">https://software.intel.com/sites/landingpage/IntrinsicsGuide/</a></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/matrix-multiplication/">Matrix-Multiplication</a></li>
      <li><a href="http://localhost:1313/tags/cache-optimization/">Cache-Optimization</a></li>
      <li><a href="http://localhost:1313/tags/simd/">SIMD</a></li>
      <li><a href="http://localhost:1313/tags/intrinsics/">Intrinsics</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="http://localhost:1313/posts/2024-04-16-hpc3-openmp-shared-memory-method/">
    <span class="title">« Prev</span>
    <br>
    <span>HPC-3-use-openmp(shared-memory-method)</span>
  </a>
  <a class="next" href="http://localhost:1313/posts/2023-04-15-hpc2-memory-hierarchy/">
    <span class="title">Next »</span>
    <br>
    <span>HPC-2-Memory-hierarchy-in-computer</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2026 <a href="http://localhost:1313/">Xi&#39;s Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu');
    if (menu) {
        
        const scrollPosition = localStorage.getItem("menu-scroll-position");
        if (scrollPosition) {
            menu.scrollLeft = parseInt(scrollPosition, 10);
        }
        
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        const html = document.querySelector("html");
        if (html.dataset.theme === "dark") {
            html.dataset.theme = 'light';
            localStorage.setItem("pref-theme", 'light');
        } else {
            html.dataset.theme = 'dark';
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
